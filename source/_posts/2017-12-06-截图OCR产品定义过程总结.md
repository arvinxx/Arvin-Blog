---

urlname: capture-ocr-demand-definition
title: 截图OCR产品定义过程总结
date: 2017-12-6
author: 空谷
header-img: http://pics.arvinx.com/2017-12-11-070327.jpg
tags: 
  - 产品定义
  - 截图
  - OCR
---

不知大家是否知道最近一款挺火的小工具 iText ？

![](http://pics.arvinx.com/2017-12-11-064645.png)

> iText 是一款从图片中识别文字的 OCR 工具。
>
> 典型使用场景：
>
> - 从扫描版 PDF 中提取文字
> - 从朋友发来的图片中识别文字
> - 从任意图片中识字
>
> 链接来源：[iText - OCR 截图识字](https://toolinbox.net/iText/)

![](https://ws1.sinaimg.cn/large/006tKfTcgy1flx120m504g30la09qkin.gif)

这个工具的作者 Jason 是我的朋友，他写过一篇 [长文](http://gitbook.cn/books/5a1eb4d55900c62956245107/index.html) 来介绍 iText 的开发过程。但是那篇文章中并没有详细叙述 iText 这个需求到底是怎么来的。而这个问题实际上需要同样长度的文章来讲述清楚，所以就有了本文。

## 截图 OCR 的需求

为什么我会挖掘到这个需求呢？一切从一个大纲软件「幕布」开始。

用一句话来介绍「幕布」这个大纲式写作工具的话，它就是文字工具的思维导图。

它有什么用呢？简单来说就是可以像思维导图那样来记录文字。**好处就是，可以用结构化的方式来记录资料，并且无限细分下去。这就非常适合来整理文本资料或者梳理知识体系，非常适用于如今的碎片化学习。**

![](http://pics.arvinx.com/2017-12-06-074237.png)

事实上我在整理自己的知识体系的时候，有两类资料是最常用的，一类是网页资料。网页资料非常容易处理，我直接复制粘贴就好。而另一类则是书籍，很多都是以 PDF 形式存在的。而中文类的 PDF，要把内容拷贝出来，就非常困难。没有 OCR 工具根本实现不了。

![](http://pics.arvinx.com/2017-12-06-074930.png)

比如说上图的部分内容我一开始是自己手打进去的。

很多不错的资料都是在一本本书籍当中的，当我尝到结构化梳理知识的甜头之后，我越发需要把一本本书中的信息梳理到我的幕布知识树中。而类似这样的次数越来越频繁，迫使我去寻找 OCR 工具。

## 现有的竞品

我一开始是找到了微软的 Onenote 自带的图像识别功能，但是它的问题有两个：一个是图片复制进去之后，我必须等图片同步完，过一段时间才能看到复制 OCR 文字的按钮，但是一方面 OneNote 上传很慢，另一方面这个识别过程也没有任何识别进度的提示，我往往要等好久才能看到复制 OCR 文字这个选项；第二个是复制出来的文字之间，必然包含着空格，这个很难受，必须做一次替换。所以貌似是最「轻量级」的解决方案，但是最后的体验却是非常「重」。当次数比较少的时候，这个功能还凑合着用，但是面对以上我所描述的需求场景时，次数变得极为频繁的时候，就变得非常「难用」了。

![](http://pics.arvinx.com/2017-12-06-075325.jpg)

然后接下来是 ABBYY FineReader、OCRKit、Prizmo 等一系列 Mac 上有名的 OCR 工具。这些工具清一色的需要**手动导入图片**，等待识别，再**导出文件**。注意！！我识别一段话需要特么截个图保存到本地，然后再导入图片，再导出文件，再打开文件，再复制进幕布！这个过程都够我全部手打完外加喝一小口奶茶了。何况 ABBYY FineReader 这个号称是识别率最高的OCR 工具，在面对中英文混合甚至一些普通中文图片的时候，识别率都差的要死。

各位看官注意，我再总结一下我的需求：**在幕布和书籍文档各占用一半屏幕的情况下，最「丝滑」地完成文字转移工作。**

![](http://pics.arvinx.com/2017-12-06-080942.png)

「丝滑」的终极要求如下：

- **识别过程中最小程度影响工作流。**（反例：FineReader 等普遍 OCR 工具和网页端的截图 OCR 工具）
- **识别出来的文字最好能够还原书籍中的样式。**比如保证段落不变，加粗不变、序号不变等（反例：OneNote 的OCR工具和 FineReader 一些特殊场景下的识别结果）

第二个要求基本上很难有完美能够实现的，但是主要的问题在于：90%以上的 OCR 工具第一条都没法满足，对整个工作流的影响太大，使用的体验太「重」。另外，FineReader 的全文识别在这个场景太重，根本用不到，实际需要的不过是一些片段。而能够满足第一条的 OCR 工具要么识别率不行，要么是太 Geek 的东西。

所以我最后得出的结论是：**Mac 端根本 「没有」 能够满足以上需求场景的 OCR识别工具。**
而面对这个需求场景下，我自己能想出来的最直观的方法是：**截图进行 OCR 识别，然后将识别出来的文字复制到剪贴板，出来的文字如果可以用就直接粘贴，如果不行就在这个面板里面稍微编辑一下再复制，这样就十分完美了。**


## 如何发现 OCR API

有人说 iText 弄的不过是一个信息不对称。但是很抱歉的是，Jason 一开始也不知道这个东西，还是我给他说的。但是怎么样发现的呢？

本来已经忘了，但是我翻了下自己的浏览器历史记录。

![](http://pics.arvinx.com/2017-12-06-082837.png)


历程大概就是用Google 搜了一堆之后试用了FineReader和一些其他的识别工具，但是不满意。过了一个月想起这个事情换了个关键词搜，结果就搜到了百度 OCR。

![](http://pics.arvinx.com/2017-12-06-065303.png)

可能当时百度 OCR 在打广告，不然如果按照今天的搜索结果来，我可能就会用腾讯的 API 了。

![](http://pics.arvinx.com/2017-12-06-083204.png)


然后我当时正好在学 JS，作为一个半吊子码农，就自己照着百度的 OCR 工具写了个脚本，连正则表达式还是照着网上抄的，更不会做什么封装。看我的记录应该是11月1号写完的，花了1个小时不到，就30行不到的代码。[CapOCR](https://github.com/arvinxx/CapOCR) 

![](http://pics.arvinx.com/2017-12-06-083429.png)

我的操作逻辑是：

> 快捷键截图 -> 按快捷键利用iPic上传图片 -> 快捷键粘贴获取的链接到第22行 -> 快捷键运行脚本 -> 快捷键复制打印值。

整个过程只需要 5 次快捷键。

![](http://pics.arvinx.com/2017-12-06-083529.png)

那为什么会用这种操作逻辑，原因就是我不懂怎么读取本地图片，更不懂怎么把截图的图片复制到剪切板。看到百度 API 可以直接用网络地址，正好我也有用 iPic 上传图片，那就偷个懒直接上传地址。然后这个可笑的正则表达式更是为了方便我直接粘贴 iPic 返回的地址，不用去手动处理掉 Markdown 语法，返回的其实就是图片的网络链接。

哪怕在真正的使用过程中，我必须要开着 Atom，但是还是用着非常爽。哪怕还是要切换一个次页面，按5下快捷键，但是整个体验已经远远甩 ABBYY FineReader 等 OCR 工具好几条街了，同时识别率惊人地好。

作为一个效率类工具的「领先用户」，我一直追求更加丝滑的用户体验。
> 关于「领先用户」，Eric von Hippel 是这么定义的：
>
> 领先用户是**在市场普及之前的数月或数年就体验需求并能从产品创新中大幅受益的用户**。
>
> 来源：THE SOURCES OF INNOVATION. Eric von Hippel.1988

但是由于我的编程水平才刚刚入门（既不懂正则，也不懂数据结构，更不懂单元测试，最多就能做个 Demo，哦不，按 CaptuocrToy 的实现程度，这个连 Demo 都算不上），很难在短时间内实现到我最终的意图。
但是我寻思着，要是能够更加爽就好了。

## 促成产品

然后我就找上了 Jason。（能认识 Jason 也是因为iPic。我用 Markdown 来进行信息的管理，处理图片的时候这个工具非常受用。)

![](http://pics.arvinx.com/2017-12-06-072531.png)

![](http://pics.arvinx.com/2017-12-06-072619.png)


再接着，Jason 的在我跟他描述完整个需求后的第四天，就把这个工具做出来了。

![](http://pics.arvinx.com/2017-12-06-072936.png)

在我跟 Jason 提这个需求（11月9日）的四天之后(11月13日)，Jason 就把内测版工具发给我测试了。

当然，我知道这个工具的开发肯定用不了四整天（实际上他也有提，原型就一天时间），但是说实话，我当时是十分惊讶的。因为我并没有指望着 Jason 会去做我的提议。我相信大部分人的想法肯定都是这样：

> “额，因为产品需求太普遍，类似于 hello world 一样，每个学习过模式识别的人都做过类似的东西，这种东西是没办法商品化的。而且市面上免费的同类产品汗牛充栋，很容易找到替代品” 


另外在写 CapOCR 时我观察到**百度 OCR 识别接口有人在2015就做过封装，放在了 V2上。**但是没有一人能够像我发现这种具体的需求场景，然后促成某个产品。如果有，我相信2015年就有 iText 这类工具出现了，但是很遗憾，两年过去了我还是没有找到。没有一个人在懂了「模式识别」或者在知道 OCR 识别 API 之后再去深入挖掘过真正的用户需求点，做个什么产品出来。
大部分程序员都是会掉入技术本身这个陷阱，这一点在我学习编程的过程中感触非常深刻。所以如果 Jason 对这个不感兴趣，我以后这方面懂了的话还是会做的，毕竟需求在那里，大家只是视而不见。

再回到实现出 iText 这个问题上，正是因为我知道大部分程序员抱有如上的想法，所以我只是抱着侥幸心理去和 Jason 提，并不指望他就会照着我的意见去做。而且目前我自己写的那个小脚本也能凑合着用。

但是让我感到惊讶的则是他真的去做了这件事情。至少在这次 iText 里，Jason 的行动非常完美地验证了他朋友圈的这句话。

> 「感受用户需求，思考解决方案，促成产品，满足需求。无Title」。


![](http://pics.arvinx.com/2017-12-06-090011.png)

作为结果，iText 可谓是开创了一个细分领域，在一片红海中找到了蓝海，没有毛病。

而且正如 Jason 在另外一贴中所述，他在完成第一版原型之后，一直在做的都是「段落识别」这个非常强烈的需求，而这个需求，是我跟他提的另外几个重要特性之一，并且足以拉开和其他 OCR 工具的距离。

当然有人可能会说，如果你把这个需求告诉我，我也一样会给你开发出来巴拉巴拉的。但是很可惜，我并不认识你。能够认识  Jason 也是因为在某些人眼中 “污染环境 Mac 环境” 的 iPic 这个工具。你们放不下身段去做一些没技术含量的工具，自然看不到那些体量巨大的用户需求，接触不到新的想法。

毕竟这不是技术上的问题，而是思维方式上的差距。技术的目的是更好的解决问题，而不是作为内耗的工具。


## 总结

虽然 Jason 没有提到我给他的启发，不过对我来说无所谓，毕竟结果是这个工具满足了我的需求，还会不断优化，那我找 Jason 目的就已经达成了。
iText 一个月6块钱不足一顿饭，但是这对我来说，却是我自我完善知识系统必不可少的工具之一。而实际上一开始就打了对折，一年也就30块，可以说是非常划算了。举个例子，用 iText 配合欧路词典我在几天之内就翻译完了一份 18 页的学术文献，没有 iText 高效提取文字，我至少要多花十几小时，并且还要有两三倍以上的耐心。这种程度的价值转换，可以说是超值了。

![](http://pics.arvinx.com/2017-12-06-104542.png)


像 iText 这样的产品需求在我脑子还有不少，只是志不在此，能力和精力也有限，所以更希望是有更多的人能够像 Jason 这样来实现更多的产品需求，并持续完善下去，给大家的生活带来更多的便利，所以当时 Jason 在朋友圈里发的这段话时，我也深有感触。

以上。